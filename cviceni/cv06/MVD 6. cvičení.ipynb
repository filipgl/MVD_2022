{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVD 6. cvičení\n",
    "\n",
    "## 1. část - PageRank\n",
    "\n",
    "Data k dnešnímu cvičení použijte z tohoto [Github repozitáře](https://github.com/chonyy/PageRank-HITS-SimRank/tree/master/dataset). Konkrétně nás budou zajímat soubory *graph_1.txt* až *graph_6.txt*. K daným datasetům je v repozitáři implementace PageRank algoritmu, každopádně se touto implementací nijak neinspirujte. \n",
    "\n",
    "Cílem je naprogramovat PageRank vektorizovaně podle přednášky, povoleno je pouze použití knihovny numpy. Parametr $\\alpha$ nastavte na hodnotu 0.2 a počet iterací bude 100. U prvních grafů uvidíte, že PageRank konverguje mnohem dříve a u těch složitějších nemusí stačit ani 100 iterací.\n",
    "\n",
    "<br>\n",
    "$\n",
    "p^{(0)} = (\\frac{1}{N}, ..., \\frac{1}{N})^T \\\\\n",
    "A = ((1-\\alpha)M + \\frac{\\alpha}{N}E) \\\\\n",
    "Opakujte: \\\\\n",
    "\\hspace{1cm}p^{(i+1)} = A^Tp^{(i)}\n",
    "$\n",
    "\n",
    "Pozor: Stránka, která nemá výstupní linky, musí mít nastavený parametr $\\alpha$ na 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import spacy\n",
    "import re\n",
    "import functools\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0656044 ]\n",
      " [0.11808792]\n",
      " [0.16007474]\n",
      " [0.19366419]\n",
      " [0.22053575]\n",
      " [0.242033  ]]\n",
      "[[0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]\n",
      " [0.2]]\n",
      "[[0.17857143]\n",
      " [0.32142857]\n",
      " [0.32142857]\n",
      " [0.17857143]]\n",
      "[[0.27257372]\n",
      " [0.15666713]\n",
      " [0.13837881]\n",
      " [0.10924643]\n",
      " [0.18531604]\n",
      " [0.06563464]\n",
      " [0.07218322]]\n"
     ]
    }
   ],
   "source": [
    "def create_graph_matrix(file_path: str) -> np.array:\n",
    "    graph_dict = {}\n",
    "    \n",
    "    with open(file_path, 'rt') as file:\n",
    "        max_num = -1\n",
    "        \n",
    "        for line in file:\n",
    "            source, dest = [int(num.strip()) - 1 for num in line.split(',')]\n",
    "\n",
    "            if source in graph_dict:\n",
    "                graph_dict[source].append(dest)\n",
    "            else:\n",
    "                graph_dict[source] = [dest]\n",
    "                \n",
    "            max_num = sorted([source, dest, max_num], reverse=True)[0]\n",
    "        \n",
    "    matrix = np.zeros((max_num + 1, max_num + 1))\n",
    "        \n",
    "    for key in graph_dict:\n",
    "        \n",
    "        if graph_dict[key]:\n",
    "            matrix[key][graph_dict[key]] = 1 / len(graph_dict[key])\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "\n",
    "alpha = 0.2\n",
    "\n",
    "for i in range(1, 5):\n",
    "    M = create_graph_matrix(f'graph_{i}.txt')\n",
    "    n = M.shape[0]\n",
    "    p = np.ones((n, 1)) / n\n",
    "\n",
    "    mask = np.sum(M, axis=1) == 0\n",
    "\n",
    "    A = (1 - alpha) * M + (alpha / n)\n",
    "    A[mask] = 1 / n\n",
    "\n",
    "    for _ in range(100):\n",
    "        p = A.transpose() @ p\n",
    "    \n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Předpokládaný výstup\n",
    "\n",
    "#### graph_1.xt\n",
    "```python\n",
    "array([[0.0656044 ],\n",
    "       [0.11808792],\n",
    "       [0.16007474],\n",
    "       [0.19366419],\n",
    "       [0.22053575],\n",
    "       [0.242033  ]])\n",
    "```\n",
    "       \n",
    "#### graph_2.txt\n",
    "```python\n",
    "array([[0.2],\n",
    "       [0.2],\n",
    "       [0.2],\n",
    "       [0.2],\n",
    "       [0.2]])\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_3.txt\n",
    "```python\n",
    "array([[0.17857143],\n",
    "       [0.32142857],\n",
    "       [0.32142857],\n",
    "       [0.17857143]])\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_4.txt\n",
    "```python\n",
    "array([[0.27257372],\n",
    "       [0.15666713],\n",
    "       [0.13837881],\n",
    "       [0.10924643],\n",
    "       [0.18531604],\n",
    "       [0.06563464],\n",
    "       [0.07218322]])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. část - HITS\n",
    "\n",
    "Použijte stejná data jako u PageRank algoritmu a počet iterací bude opět 100.\n",
    "\n",
    "Implementujte dle následujícího algoritmu:\n",
    "<br>\n",
    "\n",
    "$\n",
    "a^{(0)} = (1, ..., 1)^T, h^{(0)} = (1, ..., 1)^T\n",
    "\\\\\n",
    "Opakujte:\\\\\n",
    "    \\hspace{1cm} h^{(i+1)} = Aa^{(i)}\\\\\n",
    "    \\hspace{1cm} h^{(i+1)} = \\frac{h^{(i+1)}}{||h^{(i+1)}||_1}\\\\\n",
    "    \\hspace{1cm} a^{(i+1)} = A^Th^{(i)}\\\\\n",
    "    \\hspace{1cm} a^{(i+1)} = \\frac{a^{(i+1)}}{||a^{(i+1)}||_1}\\\\   \n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19098301]\n",
      " [0.30901699]\n",
      " [0.30901699]\n",
      " [0.19098301]]\n",
      "\n",
      "[[0.19098301]\n",
      " [0.30901699]\n",
      " [0.30901699]\n",
      " [0.19098301]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 4):\n",
    "    M = create_graph_matrix(f'graph_{i}.txt')\n",
    "    M[M != 0] = 1\n",
    "    n = M.shape[0]\n",
    "    a = np.ones((n, 1))\n",
    "    h = np.ones((n, 1))\n",
    "\n",
    "    for _ in range(100):\n",
    "        h = M @ a\n",
    "        a = M.transpose() @ h\n",
    "        \n",
    "        h = h / np.linalg.norm(h, ord=1)\n",
    "        a = a / np.linalg.norm(a, ord=1)\n",
    "        \n",
    "    \n",
    "    print(a)\n",
    "    print()\n",
    "    print(h)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Předpokládaný výstup\n",
    "\n",
    "#### graph_1.xt\n",
    "```python\n",
    "Authority:[[0. ]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]]\n",
    "Hub: [[0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0. ]]\n",
    "```\n",
    "       \n",
    "#### graph_2.txt\n",
    "```python\n",
    "Authority:[[0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]]\n",
    "Hub: [[0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]\n",
    " [0.2]]\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_3.txt\n",
    "```python\n",
    "Authority:[[0.19098301]\n",
    " [0.30901699]\n",
    " [0.30901699]\n",
    " [0.19098301]]\n",
    "Hub: [[0.19098301]\n",
    " [0.30901699]\n",
    " [0.30901699]\n",
    " [0.19098301]]\n",
    "```\n",
    "\n",
    "\n",
    "#### graph_4.txt\n",
    "```python\n",
    "Authority:[[0.13948389]\n",
    " [0.17791203]\n",
    " [0.20082321]\n",
    " [0.14017775]\n",
    " [0.20142536]\n",
    " [0.05608926]\n",
    " [0.08408849]]\n",
    "Hub: [[0.27545318]\n",
    " [0.04776231]\n",
    " [0.10868324]\n",
    " [0.19865956]\n",
    " [0.1837346 ]\n",
    " [0.11673471]\n",
    " [0.06897241]]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus - Invertovaný index pomocí MapReduce\n",
    "\n",
    "Bonusovou úlohou je vytvoření invertovaného indexu stejně, jako je uvedeno na příkladu v přednášce. Implementace nebude v standardním MapReduce frameworku, ale použijete python funkce ```map()``` a ```reduce()```. Funkci map lze poté spustit paralelně s pomocí ```Pool``` objektu z knihovny ```multiprocessing```. \n",
    "\n",
    "Vstupními daty budou Medium články, které jsme používali v posledních pár cvičeních. Z těchto článků použijte pouze nadpisy (title). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles(file_path: str) -> tuple:\n",
    "    with open(file_path, 'rt') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        data = [article for article in reader]\n",
    "        return data[0], data[1:]\n",
    "\n",
    "header, articles = load_articles('articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('D0', 1), ('D12', 2), ('D13', 1), ('D14', 1), ('D15', 1), ('D18', 1), ('D36', 1), ('D56', 1), ('D57', 1), ('D58', 1), ('D60', 1), ('D61', 1), ('D83', 1), ('D86', 1), ('D87', 1), ('D98', 1), ('D108', 1), ('D113', 1), ('D121', 1), ('D123', 2), ('D128', 1), ('D136', 1), ('D138', 1), ('D139', 1), ('D140', 1), ('D153', 1), ('D169', 1), ('D170', 1), ('D216', 1), ('D218', 1), ('D224', 1), ('D227', 1), ('D231', 1), ('D233', 1), ('D237', 1), ('D246', 1), ('D258', 1), ('D261', 1), ('D264', 1), ('D267', 1), ('D273', 1), ('D321', 1), ('D330', 1), ('D335', 1)]\n"
     ]
    }
   ],
   "source": [
    "titles = [article[4] for article in articles]\n",
    "\n",
    "\n",
    "def adjust_text(text: str, to_be_removed: re.Pattern, lemmatizer) -> list:\n",
    "    text = text.lower()\n",
    "    text = re.sub(to_be_removed, '', text)\n",
    "    text = re.sub('\\s{1,}', ' ', text)\n",
    "    \n",
    "    return [token.lemma_ for token in lemmatizer(text)]\n",
    "    \n",
    "\n",
    "def inverted_index(title: tuple) -> list:\n",
    "    index = {}\n",
    "    text_adjusted = adjust_text(\n",
    "        title[1],\n",
    "        r'[.,?!/\\\\\\\"`\\-:()\\[\\]*|—’–]',\n",
    "        spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    )\n",
    "    \n",
    "    for word in text_adjusted:\n",
    "        if word in index:\n",
    "            index[word] += 1\n",
    "        else:\n",
    "            index[word] = 1\n",
    "            \n",
    "    for key in index:\n",
    "        index[key] = [(f'D{title[0]}', index[key])]\n",
    "    \n",
    "    return index\n",
    "\n",
    "def join_indexes(index_a: dict, index_b: dict) -> dict:\n",
    "    new_index = {}\n",
    "    \n",
    "    new_index.update(index_a)\n",
    "    \n",
    "    for key in index_b:\n",
    "        if key in new_index:\n",
    "            new_index[key].extend(index_b[key])\n",
    "        else:\n",
    "            new_index[key] = [index_b[key]]\n",
    "\n",
    "    return new_index\n",
    "\n",
    "titles_with_ids = [(i, titles[i]) for i in range(len(titles))]\n",
    "\n",
    "with Pool(8) as p:\n",
    "    sub_indexes = p.map(inverted_index, titles_with_ids)\n",
    "    final_index = functools.reduce(join_indexes, sub_indexes)\n",
    "\n",
    "print(final_index['be'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Předpokládaný výstup\n",
    "\n",
    "```python\n",
    "print(inverted_index['be'])\n",
    "print(titles[12]) # zobrazení nadpisu pro kontrolu\n",
    "```\n",
    "```\n",
    "[('D0', 1), ('D12', 2), ('D13', 1), ('D14', 1), ('D15', 1), ('D18', 1), ('D36', 1), ('D56', 1), ('D57', 1), ('D58', 1), ('D60', 1), ('D61', 1), ('D83', 1), ('D86', 1), ('D87', 1), ('D98', 1), ('D108', 1), ('D113', 1), ('D121', 1), ('D123', 2), ('D128', 1), ('D136', 1), ('D138', 1), ('D139', 1), ('D140', 1), ('D153', 1), ('D169', 1), ('D170', 1), ('D216', 1), ('D218', 1), ('D224', 1), ('D227', 1), ('D231', 1), ('D233', 1), ('D237', 1), ('D246', 1), ('D258', 1), ('D261', 1), ('D264', 1), ('D267', 1), ('D273', 1), ('D321', 1), ('D330', 1), ('D335', 1)]\n",
    "```\n",
    "deep learning be go to teach we all the lesson of our life job be for machine\n",
    "\n",
    "Výstup bude identický za předpokladu použití spacy lemmatizéru. Zároveň výstup nemusí obsahovat stejný formát indexu, postačí *(index, count)*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
